{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bztUswNh_qDn",
        "outputId": "cf214414-7468-4c55-a5ef-043b99a29172"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/usharengaraju/dynamically-generated-hate-speech-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.64M/1.64M [00:00<00:00, 2.94MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/usharengaraju/dynamically-generated-hate-speech-dataset/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"usharengaraju/dynamically-generated-hate-speech-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Loading the dataset from the downloaded path\n",
        "file_path = os.path.join(path, \"2020-12-31-DynamicallyGeneratedHateDataset-entries-v0.1.csv\")\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Printing the shape of the dataset to see how many rows and columns it is having\n",
        "print(\"Shape:\", df.shape)\n",
        "\n",
        "# Printing the list of columns to understand what features the dataset is containing\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "\n",
        "# Printing the first few rows to get a quick look at how the data is looking\n",
        "print(\"\\nSample rows:\")\n",
        "print(df.head())\n",
        "\n",
        "# Checking for missing values to see if the dataset is having any null or empty cells\n",
        "print(\"\\nMissing values:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Checking the distribution of labels to understand how many hateful vs non-hateful samples are present\n",
        "print(\"\\nLabel distribution:\")\n",
        "print(df['label'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RISk23Z3_tRp",
        "outputId": "3a4763f6-e965-402e-d4fa-1a904d65357e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (40623, 11)\n",
            "Columns: ['Unnamed: 0', 'id', 'text', 'label', 'type', 'model_wrong', 'db.model_preds', 'status', 'round', 'split', 'annotator']\n",
            "\n",
            "Sample rows:\n",
            "   Unnamed: 0     id                                               text label  \\\n",
            "0           1  10000  It should be legal for a husband to rape his wife  hate   \n",
            "1           2  10001                            dalits are lowlife scum  hate   \n",
            "2           3  10002                                dalits are lowlives  hate   \n",
            "3           4  10003  It was a better world when women dare not ques...  hate   \n",
            "4           5  10004  I don't work this hard so that those immigrant...  hate   \n",
            "\n",
            "       type model_wrong  db.model_preds           status round  split  \\\n",
            "0  notgiven        True         0.97457  dynabench entry     1  train   \n",
            "1  notgiven       False         0.08233  dynabench entry     1   test   \n",
            "2  notgiven        True         0.92319  dynabench entry     1  train   \n",
            "3  notgiven        True         0.99006  dynabench entry     1   test   \n",
            "4  notgiven        True         0.98836  dynabench entry     1  train   \n",
            "\n",
            "    annotator  \n",
            "0  gnzuctwed3  \n",
            "1  cagnluiznm  \n",
            "2  cagnluiznm  \n",
            "3  gnzuctwed3  \n",
            "4  cagnluiznm  \n",
            "\n",
            "Missing values:\n",
            "Unnamed: 0            0\n",
            "id                    0\n",
            "text                  0\n",
            "label                 0\n",
            "type                  0\n",
            "model_wrong       14526\n",
            "db.model_preds    14526\n",
            "status                0\n",
            "round                 0\n",
            "split                 0\n",
            "annotator             0\n",
            "dtype: int64\n",
            "\n",
            "Label distribution:\n",
            "label\n",
            "hate       22124\n",
            "nothate    18499\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Keeping only the important columns: id, text, and label\n",
        "df = df[['id', 'text', 'label']]\n",
        "\n",
        "# Dropping rows where text or label is missing\n",
        "df = df.dropna(subset=['text', 'label'])\n",
        "\n",
        "# Converting all text to lowercase so that model is treating words consistently\n",
        "df['text'] = df['text'].str.lower()\n",
        "\n",
        "# Checking the updated shape after cleaning\n",
        "print(\"Shape after cleaning:\", df.shape)\n",
        "\n",
        "# Checking the unique labels to confirm what categories are present\n",
        "print(\"Unique labels:\", df['label'].unique())\n",
        "\n",
        "# Printing some random rows to see the cleaned text\n",
        "print(\"\\nSample after cleaning:\")\n",
        "print(df.sample(5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liJeTX9WEjqY",
        "outputId": "33be80f2-76c5-47b4-a9c5-981e0d7ef80c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape after cleaning: (40623, 3)\n",
            "Unique labels: ['hate' 'nothate']\n",
            "\n",
            "Sample after cleaning:\n",
            "           id                                               text    label\n",
            "19015  26611p  more disabled people should kill themselves no...     hate\n",
            "3638    15186  if you are a lesbian, i don't want you near me...     hate\n",
            "34716  44032p  trans ppl need to be left alone, it's not like...  nothate\n",
            "36806    5542  i hate when people call me weird just because ...  nothate\n",
            "8124    20755  there are a few things which i will definitely...     hate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splitting the dataset into train and test sets\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    df['text'], df['label'], test_size=0.2, random_state=42, stratify=df['label']\n",
        ")\n",
        "\n",
        "# Printing the sizes of train and test sets\n",
        "print(\"Training set size:\", len(train_texts))\n",
        "print(\"Testing set size:\", len(test_texts))\n",
        "\n",
        "# Showing some sample training data\n",
        "print(\"\\nSample training text and label:\")\n",
        "for i in range(3):\n",
        "    print(f\"Text: {train_texts.iloc[i]} | Label: {train_labels.iloc[i]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwCtJX2jIyEa",
        "outputId": "d607f2c5-ceed-4ce6-a8e6-edb3abc0d051"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 32498\n",
            "Testing set size: 8125\n",
            "\n",
            "Sample training text and label:\n",
            "Text: there are plenty of reasons why people act the way they do and why some communities think that they are victims all of the time.   all of these veterans taking advantage when their worth is  the genuine equivalent to an insect in the garden. | Label: nothate\n",
            "Text: why is it that when black people try to protest, not enough of them are being murdered if that is treated as riot?! | Label: hate\n",
            "Text: this is getting out of hand now, i have had 5 arguments today already just because i merely expressed my opinion, just because you think indigenous people should exist doesn\u0019t mean i do, of course i don\u0019t and i don\u0019t see why anyone would. this is so silly and is starting to exhaust me now | Label: hate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Initializing the TF-IDF Vectorizer\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "\n",
        "# Fitting on training data and transforming both train and test\n",
        "X_train = vectorizer.fit_transform(train_texts)\n",
        "X_test = vectorizer.transform(test_texts)\n",
        "\n",
        "# Printing the shapes of transformed datasets\n",
        "print(\"Training data shape after vectorization:\", X_train.shape)\n",
        "print(\"Testing data shape after vectorization:\", X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynG1uUztJV6x",
        "outputId": "d5652647-5a29-48c9-ac41-26e89ac30863"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape after vectorization: (32498, 5000)\n",
            "Testing data shape after vectorization: (8125, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Initializing Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Training the model on training data\n",
        "model.fit(X_train, train_labels)\n",
        "\n",
        "# Printing confirmation\n",
        "print(\"Model training is completed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fd6SfC8pZy4q",
        "outputId": "a68686e6-87a6-4d21-e0da-19aab8c46633"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model training is completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Making predictions on the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Printing classification report to show precision, recall, f1-score\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(test_labels, y_pred))\n",
        "\n",
        "# Printing confusion matrix to see correct vs incorrect classifications\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(test_labels, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsq-7V7wZ4Yj",
        "outputId": "0944f8f3-5935-46ce-a4af-03555bfe6d1f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.74      0.78      0.76      4425\n",
            "     nothate       0.72      0.67      0.69      3700\n",
            "\n",
            "    accuracy                           0.73      8125\n",
            "   macro avg       0.73      0.72      0.73      8125\n",
            "weighted avg       0.73      0.73      0.73      8125\n",
            "\n",
            "Confusion Matrix:\n",
            "[[3462  963]\n",
            " [1236 2464]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot_response(user_input):\n",
        "    # Converting input to lowercase\n",
        "    user_input = user_input.lower()\n",
        "\n",
        "    # Transforming input using the fitted TF-IDF vectorizer\n",
        "    vectorized_input = vectorizer.transform([user_input])\n",
        "\n",
        "    # Predicting label\n",
        "    prediction = model.predict(vectorized_input)[0]\n",
        "\n",
        "    # Filtering unsafe response if detected as hateful\n",
        "    if prediction == \"hateful\":\n",
        "        return \"This message is blocked due to unsafe or hateful content.\"\n",
        "    else:\n",
        "        return \"Message accepted: \" + user_input\n",
        "\n",
        "# Testing the chatbot\n",
        "print(chatbot_response(\"I hate you\"))\n",
        "print(chatbot_response(\"Have a nice day\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTf1lw4iJbP2",
        "outputId": "8777f8f1-ec68-4018-9b7c-aa6fcac54ff1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Message accepted: i hate you\n",
            "Message accepted: have a nice day\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a simple keyword-based filter for unsafe terms\n",
        "unsafe_keywords = unsafe_keywords = [\n",
        "    \"hate\", \"kill\", \"racist\", \"terrorist\", \"stupid\", \"idiot\",\n",
        "    \"dumb\", \"moron\", \"fool\", \"loser\", \"pathetic\", \"ugly\", \"trash\",\n",
        "    \"garbage\", \"worthless\", \"pig\", \"dog\", \"slut\", \"whore\", \"bitch\",\n",
        "    \"bastard\", \"jerk\", \"retard\", \"psycho\", \"crazy\", \"lunatic\",\n",
        "    \"violent\", \"attack\", \"murder\", \"die\", \"shoot\", \"gun\", \"knife\",\n",
        "    \"bomb\", \"explosive\", \"suicide\", \"hang\", \"burn\", \"stab\", \"rape\",\n",
        "    \"molest\", \"abuse\", \"harass\", \"slave\", \"bigot\", \"nazi\", \"fascist\",\n",
        "    \"klan\", \"islamophobic\", \"homophobic\", \"sexist\", \"misogynist\",\n",
        "    \"pedophile\", \"predator\", \"pervert\", \"incel\", \"drug\", \"addict\",\n",
        "    \"junkie\", \"drunk\", \"alcoholic\", \"fat\", \"obese\", \"cripple\", \"disease\",\"worst\"\n",
        "]\n",
        "\n",
        "\n",
        "def chatbot_response(user_input):\n",
        "    # Converting input to lowercase\n",
        "    user_input = user_input.lower()\n",
        "\n",
        "    # Transforming input using the fitted TF-IDF vectorizer\n",
        "    vectorized_input = vectorizer.transform([user_input])\n",
        "\n",
        "    # Predicting label\n",
        "    prediction = model.predict(vectorized_input)[0]\n",
        "\n",
        "    # Checking for unsafe keywords\n",
        "    if prediction == \"hateful\" or any(word in user_input for word in unsafe_keywords):\n",
        "        return \"This message is blocked due to unsafe or hateful content.\"\n",
        "    else:\n",
        "        return \"Message accepted: \" + user_input\n",
        "\n",
        "# Testing the chatbot again\n",
        "print(chatbot_response(\"I hate you\"))\n",
        "print(chatbot_response(\"You are a kind person\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPrF27qgJh40",
        "outputId": "fa49e6ee-1aea-4eaa-fc22-2990139c2829"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This message is blocked due to unsafe or hateful content.\n",
            "Message accepted: you are a kind person\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def contains_pii(text):\n",
        "    # Checking for email addresses\n",
        "    if re.search(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', text):\n",
        "        return True\n",
        "    # Checking for phone numbers (simple pattern)\n",
        "    if re.search(r'\\b\\d{10}\\b', text):\n",
        "        return True\n",
        "    # Checking for credit card numbers (simple 16-digit pattern)\n",
        "    if re.search(r'\\b\\d{16}\\b', text):\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def chatbot_response(user_input):\n",
        "    # Converting input to lowercase\n",
        "    user_input = user_input.lower()\n",
        "\n",
        "    # Checking for PII first\n",
        "    if contains_pii(user_input):\n",
        "        return \"This message is blocked due to personal information.\"\n",
        "\n",
        "    # Transforming input using TF-IDF vectorizer\n",
        "    vectorized_input = vectorizer.transform([user_input])\n",
        "\n",
        "    # Predicting label\n",
        "    prediction = model.predict(vectorized_input)[0]\n",
        "\n",
        "    # Checking for unsafe keywords\n",
        "    if prediction == \"hateful\" or any(word in user_input for word in unsafe_keywords):\n",
        "        return \"This message is blocked due to unsafe or hateful content.\"\n",
        "    else:\n",
        "        return \"Message accepted: \" + user_input\n",
        "\n",
        "# Testing the chatbot with PII\n",
        "print(chatbot_response(\"My email is test@example.com\"))\n",
        "print(chatbot_response(\"Call me at 9876543210\"))\n",
        "print(chatbot_response(\"You are stupid\"))\n",
        "print(chatbot_response(\"Good morning friend\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTQSUVXYKM9A",
        "outputId": "aa5daa3a-17f6-4548-b9d6-387b57a6b9b1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This message is blocked due to personal information.\n",
            "This message is blocked due to personal information.\n",
            "This message is blocked due to unsafe or hateful content.\n",
            "Message accepted: good morning friend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining role-based test cases\n",
        "safety_engineer_tests = [\n",
        "    \"I hate you\",\n",
        "    \"You are racist\",\n",
        "    \"Kill them all\"\n",
        "]\n",
        "\n",
        "filter_developer_tests = [\n",
        "    \"My email is user123@gmail.com\",\n",
        "    \"Here is my credit card 1234567812345678\",\n",
        "    \"Call me at 9876543210\"\n",
        "]\n",
        "\n",
        "tester_tests = [\n",
        "    \"Good morning, have a great day\",\n",
        "    \"I love programming\",\n",
        "    \"Let's go for a walk\"\n",
        "]\n",
        "\n",
        "print(\"=== Safety Engineer Testing ===\")\n",
        "for test in safety_engineer_tests:\n",
        "    print(f\"Input: {test} -> Output: {chatbot_response(test)}\")\n",
        "\n",
        "print(\"\\n=== Filter Developer Testing ===\")\n",
        "for test in filter_developer_tests:\n",
        "    print(f\"Input: {test} -> Output: {chatbot_response(test)}\")\n",
        "\n",
        "print(\"\\n=== Tester Testing ===\")\n",
        "for test in tester_tests:\n",
        "    print(f\"Input: {test} -> Output: {chatbot_response(test)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeV882xOKfDa",
        "outputId": "29c57642-ac9b-4d8c-b47f-59ee95e83be7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Safety Engineer Testing ===\n",
            "Input: I hate you -> Output: This message is blocked due to unsafe or hateful content.\n",
            "Input: You are racist -> Output: This message is blocked due to unsafe or hateful content.\n",
            "Input: Kill them all -> Output: This message is blocked due to unsafe or hateful content.\n",
            "\n",
            "=== Filter Developer Testing ===\n",
            "Input: My email is user123@gmail.com -> Output: This message is blocked due to personal information.\n",
            "Input: Here is my credit card 1234567812345678 -> Output: This message is blocked due to personal information.\n",
            "Input: Call me at 9876543210 -> Output: This message is blocked due to personal information.\n",
            "\n",
            "=== Tester Testing ===\n",
            "Input: Good morning, have a great day -> Output: Message accepted: good morning, have a great day\n",
            "Input: I love programming -> Output: Message accepted: i love programming\n",
            "Input: Let's go for a walk -> Output: Message accepted: let's go for a walk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def chatbot_interface(user_input):\n",
        "    return chatbot_response(user_input)\n",
        "\n",
        "# Creating Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=chatbot_interface,\n",
        "    inputs=\"text\",\n",
        "    outputs=\"text\",\n",
        "    title=\"Secure LLM Chatbot with Content Filtering\",\n",
        "    description=\"This chatbot is blocking unsafe responses such as hate speech and personal information.\"\n",
        ")\n",
        "\n",
        "# Launching the interface\n",
        "iface.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "ARssL9ZvK2mP",
        "outputId": "0eb0a3b8-2761-497f-9cd8-39ea1c89ddfb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://fc57141b564ebca322.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://fc57141b564ebca322.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xB3ed8i5NNDy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}